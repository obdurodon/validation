TODO
----- version 1 -------
- trap connection time out errors and report server busy, try again soon
- error files before clean files
    report html files as processed if invalid or broken links
    then list summary of files with valid html and links (just filenames)
    do same for css
- for link checking, check for 404s for absolute file paths and check manually
- clean up and add comments
- add to documentation about how includes are processed in validation (line number issues)
- look into link checking of valid link for seuss project
----- version 2 -------
- php support....eventually (option to ignore php) ----- 
    check mime type in headers (needs to be application/xhtml+xml, legacy is text/html)
    use mime type for normal xhtml/html as well

OPTIONS (all completed)
- make checking links an option to save time checking static pages? (put on hold while dealing with robots issue)
- save output to file (-s)
- switch for legacy code
- use specified directory
- project vs public directory
- debug mode with all output
- turn off html validation
- turn off css validation

directory for executable:
/usr/local/bin
