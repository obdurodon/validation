TODO
- check links
    exclude mailtos
    include redirects
    don't need anchors
    remove file:/// from links
    hack the robot checking?
        webcheck allows ignoring robots options but outputs an html file
    403 responses from actual site?
    
- add logic to check public_html directories


OPTIONS
- make checking links an option to save time checking static pages? (put on hold while dealing with robots issue)
- debug mode with all output
- save output to file (-s)
- css profile type choice?
- switch for legacy code
- use specified directory
- project vs public directory

HELPFUL COMMANDS

to check ports:
sudo netstat -nlp | grep 8888

directory for executable:
/usr/local/bin
